{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/hihic'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DFHiC/generate_train_data.py 수정\n",
    "\n",
    "import os, sys, math, random\n",
    "import numpy as np\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "\n",
    "cell = \"GM12878\"\n",
    "ref_chrom = \"hg19\"\n",
    "data_ratio = \"16\"\n",
    "\n",
    "input_data_dir = f'{path}/data'\n",
    "input_downsample_dir = f'{path}/data_downsampled_{data_ratio}'\n",
    "\n",
    "# 크로모좀 별로 matrix 만들기\n",
    "def hic_matrix_extraction(res=10000, norm_method='NONE'):\n",
    "    chrom_list = list(range(1,23))#chr1-chr22\n",
    "    hr_contacts_dict={}\n",
    "    for each in chrom_list:\n",
    "        hr_hic_file = f'{input_data_dir}/chr{each}_10kb.txt'\n",
    "        chrom_len = {item.split()[0]:int(item.strip().split()[1]) for item in open(f'{ref_chrom}.txt').readlines()} # GM12878 Hg19\n",
    "        mat_dim = int(math.ceil(chrom_len[f'chr{each}']*1.0/res))\n",
    "        hr_contact_matrix = np.zeros((mat_dim,mat_dim))\n",
    "        for line in open(hr_hic_file).readlines():\n",
    "            idx1, idx2, value = int(line.strip().split('\\t')[0]),int(line.strip().split('\\t')[1]),float(line.strip().split('\\t')[2])\n",
    "            if idx2/res>=mat_dim or idx1/res>=mat_dim:\n",
    "                continue\n",
    "            else:\n",
    "                hr_contact_matrix[int(idx1/res)][int(idx2/res)] = value\n",
    "        hr_contact_matrix+= hr_contact_matrix.T - np.diag(hr_contact_matrix.diagonal())\n",
    "        hr_contacts_dict[f'chr{each}'] = hr_contact_matrix\n",
    "    lr_contacts_dict={}\n",
    "    for each in chrom_list:\n",
    "        lr_hic_file = f'{input_downsample_dir}/chr{each}_10kb.txt'\n",
    "        chrom_len = {item.split()[0]:int(item.strip().split()[1]) for item in open('chromosome.txt').readlines()}\n",
    "        mat_dim = int(math.ceil(chrom_len[f'chr{each}']*1.0/res))\n",
    "        lr_contact_matrix = np.zeros((mat_dim,mat_dim))\n",
    "        for line in open(lr_hic_file).readlines():\n",
    "            idx1, idx2, value = int(line.strip().split('\\t')[0]),int(line.strip().split('\\t')[1]),float(line.strip().split('\\t')[2])\n",
    "            if idx2/res>=mat_dim or idx1/res>=mat_dim:\n",
    "                continue\n",
    "            else:\n",
    "                lr_contact_matrix[int(idx1/res)][int(idx2/res)] = value\n",
    "        lr_contact_matrix+= lr_contact_matrix.T - np.diag(lr_contact_matrix.diagonal())\n",
    "        lr_contacts_dict[f'chr{each}'] = lr_contact_matrix\n",
    "\n",
    "    nb_hr_contacts={item:sum(sum(hr_contacts_dict[item])) for item in hr_contacts_dict.keys()} # read 수\n",
    "    nb_lr_contacts={item:sum(sum(lr_contacts_dict[item])) for item in lr_contacts_dict.keys()}\n",
    "     \n",
    "    return hr_contacts_dict,lr_contacts_dict,nb_hr_contacts,nb_lr_contacts\n",
    "\n",
    "\n",
    "hr_contacts_dict,lr_contacts_dict,nb_hr_contacts,nb_lr_contacts = hic_matrix_extraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "submat_size = 40 # 40(DFHiC, deepHiC, HiCARN) or 28(HiCNN, SRHiC)\n",
    "\n",
    "# 매트릭스 자르기\n",
    "def crop_hic_matrix_by_chrom(chrom, size=submat_size ,thred=200, model='model'): # thred=2M/resolution\n",
    "    chr = int(chrom.split('chr')[1])\n",
    "    distance=[]\n",
    "    crop_mats_hr=[]\n",
    "    crop_mats_lr=[]\n",
    "    coordinates_hr=[]    \n",
    "    coordinates_lr=[]    \n",
    "\n",
    "    row,col = hr_contacts_dict[chrom].shape\n",
    "    if row<=thred or col<=thred: # bin 수가 200 보다 작으면 False\n",
    "        print('HiC matrix size wrong!')\n",
    "        sys.exit()\n",
    "    def quality_control(mat,thred=0.05):\n",
    "        if len(mat.nonzero()[0])<thred*mat.shape[0]*mat.shape[1]: # 숫자 있는 셀의 수가 전체의 5% 미만이면 False\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    \n",
    "    if size == 40:\n",
    "        if model == \"HiCNN\":\n",
    "            for idx1 in range(0,row-size,28):\n",
    "                for idx2 in range(0,col-size,28):\n",
    "                    if abs(idx1-idx2)<thred:\n",
    "                        if quality_control(lr_contacts_dict[chrom][idx1:idx1+size,idx2:idx2+size]):\n",
    "                            distance.append([idx1-idx2,chrom])\n",
    "                            coordinates_hr.append([chr, idx1, idx2])\n",
    "                            coordinates_lr.append([chr, idx1, idx2])\n",
    "                            \n",
    "                            hr_contact = hr_contacts_dict[chrom][idx1:idx1+size,idx2:idx2+size]\n",
    "                            lr_contact = lr_contacts_dict[chrom][idx1:idx1+size,idx2:idx2+size]\n",
    "\n",
    "                            crop_mats_hr.append(hr_contact)                \n",
    "                            crop_mats_lr.append(lr_contact)\n",
    "\n",
    "            crop_mats_hr = np.concatenate([item[np.newaxis,:] for item in crop_mats_hr],axis=0)\n",
    "            crop_mats_lr = np.concatenate([item[np.newaxis,:] for item in crop_mats_lr],axis=0)\n",
    "\n",
    "        else:        \n",
    "            for idx1 in range(0,row-size,size):\n",
    "                for idx2 in range(0,col-size,size):\n",
    "                    if abs(idx1-idx2)<thred:\n",
    "                        if quality_control(lr_contacts_dict[chrom][idx1:idx1+size,idx2:idx2+size]):\n",
    "                            distance.append([idx1-idx2,chrom])\n",
    "                            coordinates_hr.append([chr, idx1, idx2])\n",
    "                            coordinates_lr.append([chr, idx1, idx2])\n",
    "                            \n",
    "                            hr_contact = hr_contacts_dict[chrom][idx1:idx1+size,idx2:idx2+size]\n",
    "                            lr_contact = lr_contacts_dict[chrom][idx1:idx1+size,idx2:idx2+size]\n",
    "\n",
    "                            crop_mats_hr.append(hr_contact)                \n",
    "                            crop_mats_lr.append(lr_contact)\n",
    "\n",
    "            crop_mats_hr = np.concatenate([item[np.newaxis,:] for item in crop_mats_hr],axis=0)\n",
    "            crop_mats_lr = np.concatenate([item[np.newaxis,:] for item in crop_mats_lr],axis=0)                \n",
    "    else:\n",
    "        assert size == 28\n",
    "        for idx1 in range(0,row-40,size):\n",
    "            for idx2 in range(0,col-40,size):\n",
    "                if abs(idx1-idx2)<thred:\n",
    "                    if quality_control(lr_contacts_dict[chrom][idx1:idx1+size,idx2:idx2+size]):\n",
    "                        distance.append([idx1-idx2,chrom])\n",
    "                        coordinates_hr.append([chr, idx1+6, idx2+6])\n",
    "                        coordinates_lr.append([chr, idx1, idx2])\n",
    "                        \n",
    "                        hr_contact = hr_contacts_dict[chrom][idx1+6:idx1+34,idx2+6:idx2+34]\n",
    "                        lr_contact = lr_contacts_dict[chrom][idx1:idx1+40,idx2:idx2+40]\n",
    "\n",
    "                        crop_mats_hr.append(hr_contact)                \n",
    "                        crop_mats_lr.append(lr_contact)\n",
    "                      \n",
    "        crop_mats_hr = np.concatenate([item[np.newaxis,:] for item in crop_mats_hr],axis=0)\n",
    "        crop_mats_lr = np.concatenate([item[np.newaxis,:] for item in crop_mats_lr],axis=0)\n",
    "        \n",
    "    return crop_mats_hr,crop_mats_lr,distance,coordinates_hr,coordinates_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 별 데이터 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './data_DeepHiC/'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "submat_size = 40 # 40(DFHiC, deepHiC, HiCARN) or 28(HiCNN, SRHiC)\n",
    "\n",
    "def DeepHic_data_split(chrom_list):\n",
    "    random.seed(100)\n",
    "    distance_all=[]\n",
    "    assert len(chrom_list)>0\n",
    "    hr_mats,lr_mats,hr_coordinates=[],[],[]\n",
    "    for chrom in chrom_list:\n",
    "        crop_mats_hr,crop_mats_lr,distance,coordinates_hr,_ = crop_hic_matrix_by_chrom(chrom,size=submat_size,thred=200)\n",
    "        distance_all+=distance\n",
    "        hr_mats.append(crop_mats_hr)\n",
    "        lr_mats.append(crop_mats_lr)\n",
    "        hr_coordinates.append(coordinates_hr)\n",
    "    hr_mats = np.concatenate(hr_mats,axis=0)\n",
    "    lr_mats = np.concatenate(lr_mats,axis=0)\n",
    "    hr_mats=hr_mats[:,np.newaxis]\n",
    "    lr_mats=lr_mats[:,np.newaxis]\n",
    "    hr_coordinates = sum(hr_coordinates, [])\n",
    "    return hr_mats,lr_mats,hr_coordinates\n",
    "\n",
    "hr_mats_train,lr_mats_train,coordinates_train = DeepHic_data_split([f'chr{idx}' for idx in list(range(1,15))]) # train:1~15\n",
    "hr_mats_valid,lr_mats_valid,coordinates_valid = DeepHic_data_split([f'chr{idx}' for idx in list(range(15,18))]) # valid:15~17\n",
    "hr_mats_test,lr_mats_test,coordinates_test = DeepHic_data_split([f'chr{idx}' for idx in list(range(18,23))]) # test:18~22\n",
    "\n",
    "compacts = {int(k.split('chr')[1]) : np.nonzero(v)[0] for k, v in hr_contacts_dict.items()}\n",
    "size = {item.split()[0].split('chr')[1]:int(item.strip().split()[1])for item in open('chromosome.txt').readlines()}\n",
    "\n",
    "os.mkdir(save_dir+'Train_and_Validation/')\n",
    "os.mkdir(save_dir+'Test/')\n",
    "\n",
    "np.savez(save_dir+f'Train_and_Validation/train_ratio{data_ratio}.npz', data=lr_mats_train,target=hr_mats_train,inds=np.array(coordinates_train, dtype=np.int_),compacts=compacts,size=size)\n",
    "np.savez(save_dir+f'Train_and_Validation/valid_ratio{data_ratio}.npz', data=lr_mats_valid,target=hr_mats_valid,inds=np.array(coordinates_valid, dtype=np.int_),compacts=compacts,size=size)\n",
    "np.savez(save_dir+f'Test/test_ratio{data_ratio}.npz', data=lr_mats_test,target=hr_mats_test,inds=np.array(coordinates_test, dtype=np.int_),compacts=compacts,size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './data_HiCARN/'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "submat_size = 40 # 40(DFHiC, deepHiC, HiCARN) or 28(HiCNN, SRHiC)\n",
    "\n",
    "def HiCARN_data_split(chrom_list):\n",
    "    random.seed(100)\n",
    "    distance_all=[]\n",
    "    assert len(chrom_list)>0\n",
    "    hr_mats,lr_mats,hr_coordinates=[],[],[]\n",
    "    for chrom in chrom_list:\n",
    "        crop_mats_hr,crop_mats_lr,distance,coordinates_hr,_ = crop_hic_matrix_by_chrom(chrom,size=submat_size,thred=200)\n",
    "        distance_all+=distance\n",
    "        hr_mats.append(crop_mats_hr)\n",
    "        lr_mats.append(crop_mats_lr)\n",
    "        hr_coordinates.append(coordinates_hr)\n",
    "    hr_mats = np.concatenate(hr_mats,axis=0)\n",
    "    lr_mats = np.concatenate(lr_mats,axis=0)\n",
    "    hr_mats=hr_mats[:,np.newaxis]\n",
    "    lr_mats=lr_mats[:,np.newaxis]\n",
    "    hr_coordinates = sum(hr_coordinates, [])\n",
    "    return hr_mats,lr_mats,hr_coordinates\n",
    "\n",
    "hr_mats_train,lr_mats_train,coordinates_train = HiCARN_data_split([f'chr{idx}' for idx in list(range(1,15))]) # train:1~14\n",
    "hr_mats_valid,lr_mats_valid,coordinates_valid = HiCARN_data_split([f'chr{idx}' for idx in list(range(15,18))]) # valid:15~17\n",
    "hr_mats_test,lr_mats_test,coordinates_test = HiCARN_data_split([f'chr{idx}' for idx in list(range(18,23))]) # test:18~22\n",
    "\n",
    "compacts = {int(k.split('chr')[1]) : np.nonzero(v)[0] for k, v in hr_contacts_dict.items()}\n",
    "size = {item.split()[0].split('chr')[1]:int(item.strip().split()[1])for item in open('chromosome.txt').readlines()}\n",
    "\n",
    "os.mkdir(save_dir+'Train_and_Validation/')\n",
    "os.mkdir(save_dir+'Test/')\n",
    "\n",
    "np.savez(save_dir+f'Train_and_Validation/train_ratio{data_ratio}.npz', data=lr_mats_train,target=hr_mats_train,inds=np.array(coordinates_train, dtype=np.int_),compacts=compacts,size=size)\n",
    "np.savez(save_dir+f'Train_and_Validation/valid_ratio{data_ratio}.npz', data=lr_mats_valid,target=hr_mats_valid,inds=np.array(coordinates_valid, dtype=np.int_),compacts=compacts,size=size)\n",
    "np.savez(save_dir+f'Test/test_ratio{data_ratio}.npz', data=lr_mats_test,target=hr_mats_test,inds=np.array(coordinates_test, dtype=np.int_),compacts=compacts,size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './data_DFHiC/'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "submat_size = 40 # 40(DFHiC, deepHiC, HiCARN) or 28(HiCNN, SRHiC)\n",
    "\n",
    "def DFHiC_data_split(chrom_list):\n",
    "    random.seed(100)\n",
    "    distance_all=[]\n",
    "    assert len(chrom_list)>0\n",
    "    hr_mats,lr_mats=[],[]\n",
    "    for chrom in chrom_list:\n",
    "        crop_mats_hr,crop_mats_lr,distance,_,_ = crop_hic_matrix_by_chrom(chrom,size=submat_size,thred=200)\n",
    "        distance_all+=distance\n",
    "        hr_mats.append(crop_mats_hr)\n",
    "        lr_mats.append(crop_mats_lr)\n",
    "    hr_mats = np.concatenate(hr_mats,axis=0)\n",
    "    lr_mats = np.concatenate(lr_mats,axis=0)\n",
    "    hr_mats=hr_mats[:,np.newaxis]\n",
    "    lr_mats=lr_mats[:,np.newaxis]\n",
    "    hr_mats=hr_mats.transpose((0,2,3,1))\n",
    "    lr_mats=lr_mats.transpose((0,2,3,1))\n",
    "    return hr_mats,lr_mats,distance_all\n",
    "\n",
    "hr_mats_train,lr_mats_train,distance_train = DFHiC_data_split([f'chr{idx}' for idx in list(range(1,18))]) # train: 1~17\n",
    "hr_mats_test,lr_mats_test,distance_test = DFHiC_data_split([f'chr{idx}' for idx in list(range(18,23))]) # test: 18~22\n",
    "\n",
    "np.savez(save_dir+f'train_data_raw_ratio{data_ratio}.npz', train_lr=lr_mats_train,train_hr=hr_mats_train,distance=distance_train)\n",
    "np.savez(save_dir+f'test_data_raw_ratio{data_ratio}.npz', test_lr=lr_mats_test,test_hr=hr_mats_test,distance=distance_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './data_HiCNN/'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "submat_size = 40 # 40(DFHiC, deepHiC, HiCARN) or 28(HiCNN, SRHiC)\n",
    "\n",
    "def HiCNN_data_split(chrom_list):\n",
    "    random.seed(100)\n",
    "    distance_all=[]\n",
    "    assert len(chrom_list)>0\n",
    "    hr_mats,lr_mats,hr_coordinates,lr_coordinates=[],[],[],[]\n",
    "    for chrom in chrom_list:\n",
    "        crop_mats_hr,crop_mats_lr,distance,coordinates_hr,coordinates_lr = crop_hic_matrix_by_chrom(chrom,size=submat_size,thred=200,model='.')\n",
    "        distance_all+=distance\n",
    "        hr_mats.append(crop_mats_hr)\n",
    "        lr_mats.append(crop_mats_lr)\n",
    "        hr_coordinates.append(coordinates_hr)\n",
    "        lr_coordinates.append(coordinates_lr)\n",
    "    hr_mats = np.concatenate(hr_mats,axis=0)\n",
    "    lr_mats = np.concatenate(lr_mats,axis=0)\n",
    "    hr_mats=hr_mats[:,np.newaxis]\n",
    "    lr_mats=lr_mats[:,np.newaxis]\n",
    "    hr_coordinates = sum(hr_coordinates, [])\n",
    "    lr_coordinates = sum(lr_coordinates, [])\n",
    "    return hr_mats,lr_mats,hr_coordinates,lr_coordinates\n",
    "\n",
    "hr_mats_train,lr_mats_train,hr_coordinates_train,lr_coordinates_train = HiCNN_data_split([f'chr{idx}' for idx in list(range(1,15))]) # train:1~14\n",
    "hr_mats_valid,lr_mats_valid,hr_coordinates_valid,lr_coordinates_valid = HiCNN_data_split([f'chr{idx}' for idx in list(range(15,18))]) # valid:15~17\n",
    "# hr_mats_test,lr_mats_test,hr_coordinates_test,lr_coordinates_test = HiCNN_data_split([f'chr{idx}' for idx in list(range(18,23))]) # test:18~22\n",
    "\n",
    "np.save(save_dir+f'subMats_train_target_ratio{data_ratio}', hr_mats_train)\n",
    "np.save(save_dir+f'subMats_train_ratio{data_ratio}', lr_mats_train)\n",
    "np.save(save_dir+f'index_train_target', hr_coordinates_train)\n",
    "np.save(save_dir+f'index_train_data', lr_coordinates_train)\n",
    "np.save(save_dir+f'subMats_valid_target_ratio{data_ratio}', hr_mats_valid)\n",
    "np.save(save_dir+f'subMats_valid_ratio{data_ratio}', lr_mats_valid)\n",
    "np.save(save_dir+f'index_valid_target', hr_coordinates_valid)\n",
    "np.save(save_dir+f'index_valid_data', lr_coordinates_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './data_SRHiC/'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "submat_size = 28 # 40(DFHiC, deepHiC, HiCARN) or 28(HiCNN, SRHiC)\n",
    "\n",
    "def SRHiC_data_split(chrom_list):\n",
    "    random.seed(100)\n",
    "    distance_all=[]\n",
    "    assert len(chrom_list)>0\n",
    "    hr_mats,lr_mats=[],[]\n",
    "    for chrom in chrom_list:\n",
    "        crop_mats_hr,crop_mats_lr,_,_,_ = crop_hic_matrix_by_chrom(chrom,size=submat_size,thred=200)\n",
    "        hr_mats.append(crop_mats_hr)\n",
    "        lr_mats.append(crop_mats_lr)\n",
    "    hr_mats = np.concatenate(hr_mats,axis=0)\n",
    "    lr_mats = np.concatenate(lr_mats,axis=0)\n",
    "    hr_mats=hr_mats[:,np.newaxis]\n",
    "    lr_mats=lr_mats[:,np.newaxis]\n",
    "    return hr_mats,lr_mats\n",
    "\n",
    "hr_mats_train,lr_mats_train = SRHiC_data_split([f'chr{idx}' for idx in list(range(1,18))]) # train: 1~17\n",
    "hr_mats_test,lr_mats_test = SRHiC_data_split([f'chr{idx}' for idx in list(range(18,23))]) # valid:15~17\n",
    "\n",
    "train = np.concatenate((lr_mats_train[:,0,:,:], np.concatenate((hr_mats_train[:,0,:,:],np.zeros((hr_mats_train.shape[0],12,28))), axis=1)), axis=2)\n",
    "valid = np.concatenate((lr_mats_test[:,0,:,:], np.concatenate((hr_mats_test[:,0,:,:],np.zeros((hr_mats_test.shape[0],12,28))), axis=1)), axis=2)\n",
    "\n",
    "np.save(save_dir+f'train_data_raw_ratio{data_ratio}', train)\n",
    "np.save(save_dir+f'valid_data_raw_ratio{data_ratio}', valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './data_hicplus/'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "submat_size = 40 # 40(DFHiC, deepHiC, HiCARN, hicplus) or 28(HiCNN, SRHiC)\n",
    "\n",
    "def hicplus_data_split(chrom_list):\n",
    "    random.seed(100)\n",
    "    distance_all=[]\n",
    "    assert len(chrom_list)>0\n",
    "    hr_mats,lr_mats,hr_coordinates,lr_coordinates=[],[],[],[]\n",
    "    for chrom in chrom_list:\n",
    "        crop_mats_hr,crop_mats_lr,distance,coordinates_hr,coordinates_lr = crop_hic_matrix_by_chrom(chrom,size=submat_size,thred=200,model='model')\n",
    "        distance_all+=distance\n",
    "        hr_mats.append(crop_mats_hr)\n",
    "        lr_mats.append(crop_mats_lr)\n",
    "        hr_coordinates.append(coordinates_hr)\n",
    "        lr_coordinates.append(coordinates_lr)\n",
    "    hr_mats = np.concatenate(hr_mats,axis=0)\n",
    "    lr_mats = np.concatenate(lr_mats,axis=0)\n",
    "    hr_mats=hr_mats[:,np.newaxis]\n",
    "    lr_mats=lr_mats[:,np.newaxis]\n",
    "    hr_coordinates = sum(hr_coordinates, [])\n",
    "    lr_coordinates = sum(lr_coordinates, [])\n",
    "    return hr_mats,lr_mats,hr_coordinates,lr_coordinates\n",
    "\n",
    "hr_mats_train,lr_mats_train,hr_coordinates_train,lr_coordinates_train = hicplus_data_split([f'chr{idx}' for idx in list(range(1,18))]) # train:1~17\n",
    "hr_mats_test,lr_mats_test,hr_coordinates_test,lr_coordinates_test = hicplus_data_split([f'chr{idx}' for idx in list(range(18,23))]) # test:18~22\n",
    "\n",
    "np.save(save_dir+f'subMats_train_target_ratio{data_ratio}', hr_mats_train)\n",
    "np.save(save_dir+f'subMats_train_ratio{data_ratio}', lr_mats_train)\n",
    "np.save(save_dir+f'index_train_target', hr_coordinates_train)\n",
    "np.save(save_dir+f'index_train_data', lr_coordinates_train)\n",
    "np.save(save_dir+f'subMats_test_target_ratio{data_ratio}', hr_mats_test)\n",
    "np.save(save_dir+f'subMats_test_ratio{data_ratio}', lr_mats_test)\n",
    "np.save(save_dir+f'index_test_target', hr_coordinates_test)\n",
    "np.save(save_dir+f'index_test_data', lr_coordinates_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffuser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
